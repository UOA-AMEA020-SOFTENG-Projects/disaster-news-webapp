{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV Project Statistical Hypothesis Testing\n",
    "\n",
    "SUS survey ratings collected from a sample of 20 participants. Collected over a period of 3 weeks. After performance specific tasks, participants were asked to rate the usability of two prototype disaster news apps. The first app was a map interface and the second app was a newsfeed interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import shapiro, ttest_rel, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ratings = pd.read_csv(\"map.csv\", header=None)\n",
    "newsfeed_ratings = pd.read_csv(\"newsfeed.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SUS(row):\n",
    "    odd_scores = row.values[::2] - 1\n",
    "    even_scores = 5 - row.values[1::2]\n",
    "    return 2.5 * (odd_scores.sum() + even_scores.sum())\n",
    "\n",
    "map_ratings[\"SUS_score\"] = map_ratings.apply(compute_SUS, axis=1)\n",
    "newsfeed_ratings[\"SUS_score\"] = newsfeed_ratings.apply(compute_SUS, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Removed two outliers from the dataset rows `1` and `13` (index starts from `0`)\n",
    "\n",
    "Row `1`: map SUS score was significantly lower than the rest of the dataset.\n",
    "\n",
    "Row `13`: newsfeed SUS score was `100`, meaning perfect percieved usability, significantly greater than the rest of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_outlier = map_ratings.iloc[1][\"SUS_score\"]\n",
    "newsfeed_outlier = newsfeed_ratings.iloc[13][\"SUS_score\"]\n",
    "print(f\"Map SUS score outlier: {map_outlier}\")\n",
    "print(f\"Newsfeed SUS score outlier: {newsfeed_outlier}\")\n",
    "\n",
    "map_ratings.drop([1, 13], inplace=True)\n",
    "newsfeed_ratings.drop([1, 13], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = [map_ratings['SUS_score'], newsfeed_ratings['SUS_score']]\n",
    "plt.boxplot(combined_data, widths=0.5)\n",
    "plt.xticks([1, 2], [\"Map\", \"Newsfeed\"])\n",
    "plt.title(\"Comparison of Interface SUS Scores\")\n",
    "plt.ylabel(\"SUS Score\")\n",
    "\n",
    "scatter_colors = ['#ff6766', '#567f98']\n",
    "for i, data_point in enumerate(combined_data, 1):\n",
    "    x_positions = np.random.normal(i, 0.1, len(data_point))\n",
    "    plt.scatter(x_positions, data_point, c=scatter_colors[i-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_mean = map_ratings[\"SUS_score\"].mean()\n",
    "newsfeed_mean = newsfeed_ratings[\"SUS_score\"].mean()\n",
    "print(f\"Map SUS mean: {map_mean}\")\n",
    "print(f\"Newsfeed SUS mean: {newsfeed_mean}\") \n",
    "\n",
    "map_median = map_ratings[\"SUS_score\"].median()\n",
    "newsfeed_median = newsfeed_ratings[\"SUS_score\"].median()\n",
    "print(f\"Map SUS median: {map_median}\")\n",
    "print(f\"Newsfeed SUS median: {newsfeed_median}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_scores = map_ratings['SUS_score'].tolist()\n",
    "newsfeed_scores = newsfeed_ratings['SUS_score'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality Assumption\n",
    "\n",
    "Test for normality using Shapiro-Wilk test yielded a pvalue of `0.168`. Also, through visual inspection indicates that the data is normally distributed. Therefore, parametric paired t-testing can commence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = map_ratings['SUS_score'] - newsfeed_ratings['SUS_score']\n",
    "plt.hist(differences)\n",
    "plt.title(\"Histogram of SUS Score Differences\")\n",
    "plt.xlabel(\"Difference\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "result = shapiro(differences)\n",
    "print(f'Shapiro-Wilk Test Statistic: {result.statistic}')\n",
    "print(f'P-value for Normality: {result.pvalue}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences Analysis\n",
    "\n",
    "Just over half of participants rated the map interface with a higher SUS score than the newsfeed interface. Only `1` participant rating the SUS score equally, which is expected as it is rare for this to occur. This means there is still a significant portion of the population which rated SUS score of the newsfeed interface higher than the map interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Map better', 'Equal', 'Newsfeed better']\n",
    "sizes = [np.sum(differences > 0), np.sum(differences == 0), np.sum(differences < 0)]\n",
    "colors = ['#ff6766', '#d9d9d9', '#81ccb9']\n",
    "\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "plt.title(\"Participant invidual SUS Score differences\")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing\n",
    "\n",
    "Participants are evaluating two different apps using the SUS (System Usability Scale) survey, Each participant provides two scores: one for each app. Therefore, we are dealing with paired or related samples. Paired t-test and confidence interval are used to compare the mean difference between the two apps. The following is our hypotheses:\n",
    "\n",
    "H0: The null hypothesis is that the mean difference between the two apps is zero. \n",
    "\n",
    "H1: The alternative hypothesis is that the mean difference is not zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ttest_rel(map_scores, newsfeed_scores)\n",
    "print(f\"T-statistic: {result.statistic}\")\n",
    "print(f\"P-value: {result.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = np.mean(differences)\n",
    "std_diff = np.std(differences, ddof=1)\n",
    "n = len(differences)\n",
    "se_diff = std_diff / np.sqrt(n)\n",
    "t_critical = t.ppf(1 - 0.025, df=n-1)\n",
    "\n",
    "ci_lower = mean_diff - t_critical * se_diff\n",
    "ci_upper = mean_diff + t_critical * se_diff\n",
    "\n",
    "print(f\"95% Confidence Interval for the difference: ({ci_lower:.2f}, {ci_upper:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The p-value of 0.32 suggests that the observed difference between the two groups is not statistically significant at the traditional 0.05 alpha level. In other words, assuming there's no true difference between the groups in the population, there's a 32% probability of observing a difference as extreme as (or more extreme than) what was observed in the sample purely due to random chance.\n",
    "\n",
    "The fact that the 95% CI for the difference includes zero aligns with the non-significant p-value. If the CI includes zero, it indicates that the difference is not statistically significant at the 0.05 level.\n",
    "\n",
    "Even though the difference isn't statistically significant, the CI still gives an estimate of the possible range of true differences. The range (-3.82, 10.76) means that while the true difference might favor one group, it might also favor the other, or there might be negligible difference.\n",
    "\n",
    "The combination of the p-value and the CI suggests that while there's no clear statistical evidence of a difference, there's still some uncertainty about the true size and direction of any potential difference. This might be indicative of either the variability in the data or the sample size not being large enough to detect a smaller effect.\n",
    "\n",
    "Future research directions could include increasing the sample size. It would be beneficial to test the two apps long term and have participants answer the SUS survey at different times to minise any bias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
